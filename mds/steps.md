Step A: The "Mock" Coach (Days 1-3)Objective: Establish a reliable "Sensory Input" loop.Isolate Coordinates: Copy screen_coords.py into a new project.Resolution Scaling: If you play on anything other than 1920x1080, write a scaling function using vec2.py.$$\text{ScaledCoord} = \text{HardcodedCoord} \times \left( \frac{\text{CurrentResolution}}{\text{BaseResolution}} \right)$$The Capture Loop: Use MSS (from your findings) to grab frames. Feed the "Shop" region into the OCR script you found.The "Ear-Whisperer" Beta: Write a simple script that prints a JSON of your current game state every 2 seconds.Goal: Successfully detect "Gold: 50" and "Shop: [Darius, Draven, Lux, ...]" without crashing.

Step B: The RAG Integration (Days 4-7)Objective: Replace the hard-coded comps.py with a live "Source of Truth."Kill the Hardcoding: Delete the contents of comps.py and game_assets.py.Data Ingestion: Write a script to pull the Community Dragon (CDragon) JSONs. This is the official game data.Scrape the Meta: Write a small scraper for Tactics.tools.What to pull: Unit win rates, best item pairings, and "Top Comps."Vectorize for RAG: Use LangChain to store this in a ChromaDB.The Advice Engine: When your "Mock Coach" sees your items/board, it queries the DB: "What is the S-Tier line for these items?"

Step C: The Vision Upgrade (Week 2+)Objective: Replace brittle OCR with a professional CV pipeline.Generate a Fingerprint Manifest: Instead of training a model from scratch, take the champion icons you scraped from CDragon and generate a Perceptual Hash (pHash) for each one.Visual Matching:Capture the shop icon.Calculate its pHash.Compare it against your manifest using Hamming distance.Why this wins: If Riot changes a champion's name or font, your OCR breaks. If you use pHash, you just update the icon folder. It is truly set-agnostic.